{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI Notebook  \n",
    "This notebook demonstrates the usage of synchronous and asynchronous OpenAI endpoints integrated with Javelin.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Synchronous OpenAI client...\n",
      "sk-proj-bF54IwKWyN9SbdpGrnS4T3BlbkFJ6PyfIsqqoifSnyMzx9ae\n",
      "OpenAI: 1 - Chat completions\n",
      "{\n",
      "  \"id\": \"chatcmpl-AzKXhek0wiLY41sTGfT6qBW5sT1EA\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"message\": {\n",
      "        \"content\": \"Machine learning is a subset of artificial intelligence (AI) that involves constructing algorithms and statistical models that allow computers to learn from and make predictions or decisions based on data without being explicitly programmed. Machine learning algorithms identify patterns in data and use that information to improve their performance over time. This technology is used in a wide range of applications, including image and speech recognition, recommendation systems, fraud detection, medical diagnosis, and many others.\",\n",
      "        \"refusal\": null,\n",
      "        \"role\": \"assistant\",\n",
      "        \"audio\": null,\n",
      "        \"function_call\": null,\n",
      "        \"tool_calls\": null\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1739180337,\n",
      "  \"model\": \"gpt-3.5-turbo-0125\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"service_tier\": \"default\",\n",
      "  \"system_fingerprint\": null,\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 86,\n",
      "    \"prompt_tokens\": 12,\n",
      "    \"total_tokens\": 98,\n",
      "    \"completion_tokens_details\": {\n",
      "      \"accepted_prediction_tokens\": 0,\n",
      "      \"audio_tokens\": 0,\n",
      "      \"reasoning_tokens\": 0,\n",
      "      \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens_details\": {\n",
      "      \"audio_tokens\": 0,\n",
      "      \"cached_tokens\": 0\n",
      "    }\n",
      "  },\n",
      "  \"javelin\": {\n",
      "    \"archive_enabled\": true,\n",
      "    \"correlation_id\": \"01JKQKKTFANF3PA3GB7866VMGV\",\n",
      "    \"model_endpoint_url\": \"https://api.openai.com/v1/chat/completions\",\n",
      "    \"model_latency\": \"943.195026ms\",\n",
      "    \"model_name\": \"gpt-3.5-turbo\",\n",
      "    \"processor_outputs\": {\n",
      "      \"request.chain.archive_processor_20250210093858.597264197\": {\n",
      "        \"duration\": \"4.985534ms\",\n",
      "        \"success\": \"successfully archived memory\"\n",
      "      },\n",
      "      \"request.chain.dlp_gcp_processor_20250210093858.597381862\": {\n",
      "        \"duration\": \"66.605µs\",\n",
      "        \"skipped\": \"warn: sensitive data protection is disabled for route:openai-univ\"\n",
      "      },\n",
      "      \"request.chain.promptinjectiondetection_processor_20250210093858.597346110\": {\n",
      "        \"duration\": \"82.097µs\",\n",
      "        \"skipped\": \"warn: prompt safety is disabled for route:openai-univ\"\n",
      "      },\n",
      "      \"request.chain.ratelimit_processor_20250210093858.597364325\": {\n",
      "        \"duration\": \"52.993µs\"\n",
      "      },\n",
      "      \"request.chain.secrets_processor_20250210093858.597439995\": {\n",
      "        \"duration\": \"10.313µs\"\n",
      "      },\n",
      "      \"response.chain.response_processor_20250210093858.597321120\": {\n",
      "        \"duration\": \"0s\"\n",
      "      },\n",
      "      \"response.chain.trustsafety_processor_20250210093858.597283100\": {\n",
      "        \"duration\": \"53.485µs\",\n",
      "        \"skipped\": \"warn: trust safety is disabled for route:openai-univ\"\n",
      "      }\n",
      "    },\n",
      "    \"route_name\": \"openai-univ\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import asyncio\n",
    "from openai import OpenAI\n",
    "from openai import AsyncOpenAI\n",
    "from openai import AzureOpenAI  # Imported for consistency, though not used in this notebook\n",
    "import dotenv\n",
    "from javelin_sdk import (\n",
    "    JavelinClient,\n",
    "    JavelinConfig,\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# Synchronous OpenAI Example\n",
    "# -------------------------------\n",
    "print(\"Initializing Synchronous OpenAI client...\")\n",
    "\n",
    "# Create OpenAI client using the API key from the environment variable\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "print(openai_api_key)\n",
    "openai_client = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "# Initialize Javelin Client with your API key and base URL\n",
    "javelin_api_key = os.environ['JAVELIN_API_KEY'] = \"\"\n",
    "config = JavelinConfig(\n",
    "    base_url=\"https://api-dev.javelin.live\",\n",
    "    # Uncomment the following line to use a local server:\n",
    "    # base_url=\"http://localhost:8000\",\n",
    "    javelin_api_key=javelin_api_key,\n",
    ")\n",
    "client = JavelinClient(config)\n",
    "\n",
    "# Register the OpenAI client with Javelin using the route name \"openai\"\n",
    "client.register_openai(openai_client, route_name=\"openai-univ\")\n",
    "\n",
    "# --- Call OpenAI Endpoints ---\n",
    "\n",
    "print(\"OpenAI: 1 - Chat completions\")\n",
    "chat_completions = openai_client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"What is machine learning?\"}],\n",
    ")\n",
    "print(chat_completions.model_dump_json(indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"OpenAI: 2 - Completions\")\n",
    "completions = openai_client.completions.create(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    prompt=\"What is machine learning?\",\n",
    "    max_tokens=7,\n",
    "    temperature=0\n",
    ")\n",
    "print(completions.model_dump_json(indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"OpenAI: 3 - Embeddings\")\n",
    "embeddings = openai_client.embeddings.create(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    input=\"The food was delicious and the waiter...\",\n",
    "    encoding_format=\"float\"\n",
    ")\n",
    "print(embeddings.model_dump_json(indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"OpenAI: 4 - Streaming\")\n",
    "stream = openai_client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Say this is a test\"}\n",
    "    ],\n",
    "    model=\"gpt-4o\",\n",
    "    stream=True,\n",
    ")\n",
    "for chunk in stream:\n",
    "    # Debug print: show each streaming chunk\n",
    "    print(chunk.choices[0].delta.content or \"\", end=\"\")\n",
    "\n",
    "# Prints two blank lines for clarity\n",
    "print(\"\\n\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Asynchronous OpenAI Example\n",
    "# -------------------------------\n",
    "print(\"Initializing AsyncOpenAI client...\")\n",
    "\n",
    "# Create AsyncOpenAI client\n",
    "openai_async_client = AsyncOpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),  # This is the default and can be omitted\n",
    ")\n",
    "\n",
    "# Reinitialize Javelin Client for Async usage (using the same config)\n",
    "javelin_api_key = os.getenv('JAVELIN_API_KEY')\n",
    "config = JavelinConfig(\n",
    "    base_url=\"https://api-dev.javelin.live\",\n",
    "    # base_url=\"http://localhost:8000\",\n",
    "    javelin_api_key=javelin_api_key,\n",
    ")\n",
    "client = JavelinClient(config)\n",
    "client.register_openai(openai_async_client, route_name=\"openai\")\n",
    "\n",
    "async def main() -> None:\n",
    "    chat_completion = await openai_async_client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": \"Say this is a test\"}\n",
    "        ],\n",
    "        model=\"gpt-4o\",\n",
    "    )\n",
    "    print(chat_completion.model_dump_json(indent=2))\n",
    "\n",
    "print(\"AsyncOpenAI: 5 - Chat completions\")\n",
    "asyncio.run(main())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
