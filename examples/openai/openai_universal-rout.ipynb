{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI Notebook  \n",
    "This notebook demonstrates the usage of synchronous and asynchronous OpenAI endpoints integrated with Javelin.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Synchronous OpenAI client...\n",
      "sk-proj-bF54IwKWyN9SbdpGrnS4T3BlbkFJ6PyfIsqqoifSnyMzx9ae\n",
      "OpenAI: 1 - Chat completions\n",
      "{\n",
      "  \"id\": \"chatcmpl-AzSpIE70igz2obmW1QmIOPyQBjAl3\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"message\": {\n",
      "        \"content\": \"Machine learning is a subset of artificial intelligence that involves the development of algorithms and models that allow computers to learn from data and make predictions or decisions without being explicitly programmed. In other words, machine learning enables computers to learn and improve from experience, rather than being programmed with specific instructions for every task. It is used in various applications, such as image and speech recognition, recommendation systems, and predictive analytics.\",\n",
      "        \"refusal\": null,\n",
      "        \"role\": \"assistant\",\n",
      "        \"audio\": null,\n",
      "        \"function_call\": null,\n",
      "        \"tool_calls\": null\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1739212180,\n",
      "  \"model\": \"gpt-3.5-turbo-0125\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"service_tier\": \"default\",\n",
      "  \"system_fingerprint\": null,\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 81,\n",
      "    \"prompt_tokens\": 12,\n",
      "    \"total_tokens\": 93,\n",
      "    \"completion_tokens_details\": {\n",
      "      \"accepted_prediction_tokens\": 0,\n",
      "      \"audio_tokens\": 0,\n",
      "      \"reasoning_tokens\": 0,\n",
      "      \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens_details\": {\n",
      "      \"audio_tokens\": 0,\n",
      "      \"cached_tokens\": 0\n",
      "    }\n",
      "  },\n",
      "  \"javelin\": {\n",
      "    \"archive_enabled\": true,\n",
      "    \"correlation_id\": \"01JKRHZHQVKT52HB1DZ66JS2J2\",\n",
      "    \"model_endpoint_url\": \"https://api.openai.com/v1/chat/completions\",\n",
      "    \"model_latency\": \"1.718661856s\",\n",
      "    \"model_name\": \"gpt-3.5-turbo\",\n",
      "    \"processor_outputs\": {\n",
      "      \"request.chain.archive_processor_20250210182940.965083629\": {\n",
      "        \"duration\": \"15.043426ms\",\n",
      "        \"success\": \"successfully archived memory\"\n",
      "      },\n",
      "      \"request.chain.dlp_gcp_processor_20250210182940.965023472\": {\n",
      "        \"duration\": \"90.247µs\",\n",
      "        \"skipped\": \"warn: sensitive data protection is disabled for route:openai-univ\"\n",
      "      },\n",
      "      \"request.chain.promptinjectiondetection_processor_20250210182940.965147011\": {\n",
      "        \"duration\": \"394.597µs\",\n",
      "        \"skipped\": \"warn: prompt safety is disabled for route:openai-univ\"\n",
      "      },\n",
      "      \"request.chain.ratelimit_processor_20250210182940.965168720\": {\n",
      "        \"duration\": \"2.675224ms\"\n",
      "      },\n",
      "      \"request.chain.secrets_processor_20250210182940.965039958\": {\n",
      "        \"duration\": \"16.296µs\"\n",
      "      },\n",
      "      \"response.chain.response_processor_20250210182940.965123146\": {\n",
      "        \"duration\": \"0s\"\n",
      "      },\n",
      "      \"response.chain.trustsafety_processor_20250210182940.965105478\": {\n",
      "        \"duration\": \"70.339µs\",\n",
      "        \"skipped\": \"warn: trust safety is disabled for route:openai-univ\"\n",
      "      }\n",
      "    },\n",
      "    \"route_name\": \"openai-univ\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import asyncio\n",
    "from openai import OpenAI\n",
    "from openai import AsyncOpenAI\n",
    "from openai import AzureOpenAI  # Imported for consistency, though not used in this notebook\n",
    "import dotenv\n",
    "from javelin_sdk import (\n",
    "    JavelinClient,\n",
    "    JavelinConfig,\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# Synchronous OpenAI Example\n",
    "# -------------------------------\n",
    "print(\"Initializing Synchronous OpenAI client...\")\n",
    "\n",
    "# Create OpenAI client using the API key from the environment variable\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "print(openai_api_key)\n",
    "openai_client = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "# Initialize Javelin Client with your API key and base URL\n",
    "javelin_api_key = os.environ['JAVELIN_API_KEY'] = \"\"\n",
    "config = JavelinConfig(\n",
    "    base_url=\"https://api-dev.javelin.live\",\n",
    "    # Uncomment the following line to use a local server:\n",
    "    # base_url=\"http://localhost:8000\",\n",
    "    javelin_api_key=javelin_api_key,\n",
    ")\n",
    "client = JavelinClient(config)\n",
    "\n",
    "# Register the OpenAI client with Javelin using the route name \"openai\"\n",
    "client.register_openai(openai_client, route_name=\"openai-univ\")\n",
    "\n",
    "# --- Call OpenAI Endpoints ---\n",
    "\n",
    "print(\"OpenAI: 1 - Chat completions\")\n",
    "chat_completions = openai_client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"What is machine learning?\"}],\n",
    ")\n",
    "print(chat_completions.model_dump_json(indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"OpenAI: 2 - Completions\")\n",
    "completions = openai_client.completions.create(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    prompt=\"What is machine learning?\",\n",
    "    max_tokens=7,\n",
    "    temperature=0\n",
    ")\n",
    "print(completions.model_dump_json(indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"OpenAI: 3 - Embeddings\")\n",
    "embeddings = openai_client.embeddings.create(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    input=\"The food was delicious and the waiter...\",\n",
    "    encoding_format=\"float\"\n",
    ")\n",
    "print(embeddings.model_dump_json(indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"OpenAI: 4 - Streaming\")\n",
    "stream = openai_client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Say this is a test\"}\n",
    "    ],\n",
    "    model=\"gpt-4o\",\n",
    "    stream=True,\n",
    ")\n",
    "for chunk in stream:\n",
    "    # Debug print: show each streaming chunk\n",
    "    print(chunk.choices[0].delta.content or \"\", end=\"\")\n",
    "\n",
    "# Prints two blank lines for clarity\n",
    "print(\"\\n\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Asynchronous OpenAI Example\n",
    "# -------------------------------\n",
    "print(\"Initializing AsyncOpenAI client...\")\n",
    "\n",
    "# Create AsyncOpenAI client\n",
    "openai_async_client = AsyncOpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),  # This is the default and can be omitted\n",
    ")\n",
    "\n",
    "# Reinitialize Javelin Client for Async usage (using the same config)\n",
    "javelin_api_key = os.getenv('JAVELIN_API_KEY')\n",
    "config = JavelinConfig(\n",
    "    javelin_api_key=javelin_api_key,\n",
    ")\n",
    "client = JavelinClient(config)\n",
    "client.register_openai(openai_async_client, route_name=\"openai\")\n",
    "\n",
    "async def main() -> None:\n",
    "    chat_completion = await openai_async_client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": \"Say this is a test\"}\n",
    "        ],\n",
    "        model=\"gpt-4o\",\n",
    "    )\n",
    "    print(chat_completion.model_dump_json(indent=2))\n",
    "\n",
    "print(\"AsyncOpenAI: 5 - Chat completions\")\n",
    "asyncio.run(main())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
