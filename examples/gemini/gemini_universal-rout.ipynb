{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gemini Notebook  \n",
    "This notebook demonstrates the usage of Gemini APIs integrated with Javelin.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Gemini client...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "GEMINI_API_KEY is not set!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m gemini_api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGEMINI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m gemini_api_key:\n\u001b[0;32m---> 17\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGEMINI_API_KEY is not set!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGemini API Key loaded successfully.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Create an OpenAI client configured for Gemini with the appropriate base URL\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: GEMINI_API_KEY is not set!"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from javelin_sdk import (\n",
    "    JavelinClient,\n",
    "    JavelinConfig,\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# Gemini API Example\n",
    "# -------------------------------\n",
    "print(\"Initializing Gemini client...\")\n",
    "\n",
    "# Retrieve the Gemini API key from the environment variable\n",
    "gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "if not gemini_api_key:\n",
    "    raise ValueError(\"GEMINI_API_KEY is not set!\")\n",
    "print(\"Gemini API Key loaded successfully.\")\n",
    "# Create an OpenAI client configured for Gemini with the appropriate base URL\n",
    "openai_client = OpenAI(\n",
    "    api_key=gemini_api_key,\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")\n",
    "\n",
    "# Initialize the Javelin Client (using the same javelin_api_key as before)\n",
    "javelin_api_key = os.getenv('JAVELIN_API_KEY')\n",
    "config = JavelinConfig(\n",
    "    base_url=\"https://api-dev.javelin.live\",\n",
    "    # Uncomment the following line to use a local server:\n",
    "    # base_url=\"http://localhost:8000\",\n",
    "    javelin_api_key=javelin_api_key,\n",
    ")\n",
    "client = JavelinClient(config)\n",
    "\n",
    "# Register the Gemini client with Javelin\n",
    "client.register_gemini(openai_client, route_name=\"testing\")\n",
    "\n",
    "print(\"Gemini: 1 - Chat completions\")\n",
    "response = openai_client.chat.completions.create(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    n=1,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Explain to me how AI works\"}\n",
    "    ]\n",
    ")\n",
    "print(response.model_dump_json(indent=2))\n",
    "\n",
    "print(\"Gemini: 2 - Streaming\")\n",
    "response = openai_client.chat.completions.create(\n",
    "  model=\"gemini-1.5-flash\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hello!\"}\n",
    "  ],\n",
    "  stream=True\n",
    ")\n",
    "for chunk in response:\n",
    "    # Debug print: output each streaming chunk's delta\n",
    "    print(chunk.choices[0].delta)\n",
    "\n",
    "print(\"Gemini: 3 - Function calling\")\n",
    "tools = [\n",
    "  {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "      \"name\": \"get_weather\",\n",
    "      \"description\": \"Get the weather in a given location\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"location\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The city and state, e.g. Chicago, IL\",\n",
    "          },\n",
    "          \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "        },\n",
    "        \"required\": [\"location\"],\n",
    "      },\n",
    "    }\n",
    "  }\n",
    "]\n",
    "messages = [{\"role\": \"user\", \"content\": \"What's the weather like in Chicago today?\"}]\n",
    "response = openai_client.chat.completions.create(\n",
    "  model=\"gemini-1.5-flash\",\n",
    "  messages=messages,\n",
    "  tools=tools,\n",
    "  tool_choice=\"auto\"\n",
    ")\n",
    "print(response.model_dump_json(indent=2))\n",
    "\n",
    "# --- Gemini Image Understanding Example (Commented Out) ---\n",
    "'''\n",
    "print(\"Gemini: 4 - Image understanding\")\n",
    "import base64\n",
    "\n",
    "# Function to encode the image in base64 format\n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "# Convert an image to a base64 string\n",
    "base64_image = encode_image(\"Path/to/agi/image.jpeg\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gemini-1.5-flash\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\"type\": \"text\", \"text\": \"What is in this image?\"},\n",
    "        {\"type\": \"image_url\", \"image_url\": {\"url\":  f\"data:image/jpeg;base64,{base64_image}\"}},\n",
    "      ],\n",
    "    }\n",
    "  ],\n",
    ")\n",
    "print(response.model_dump_json(indent=2))\n",
    "'''\n",
    "\n",
    "print(\"Gemini: 5 - Structured output\")\n",
    "from pydantic import BaseModel\n",
    "class CalendarEvent(BaseModel):\n",
    "    name: str\n",
    "    date: str\n",
    "    participants: list[str]\n",
    "\n",
    "completion = openai_client.beta.chat.completions.parse(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Extract the event information.\"},\n",
    "        {\"role\": \"user\", \"content\": \"John and Susan are going to an AI conference on Friday.\"},\n",
    "    ],\n",
    "    response_format=CalendarEvent,\n",
    ")\n",
    "print(completion.model_dump_json(indent=2))\n",
    "\n",
    "print(\"Gemini: 6 - Embeddings\")\n",
    "response = openai_client.embeddings.create(\n",
    "    input=\"Your text string goes here\",\n",
    "    model=\"text-embedding-004\"\n",
    ")\n",
    "print(response.model_dump_json(indent=2))\n",
    "\n",
    "# Prints two blank lines for clarity\n",
    "print(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
